{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.11.0\n",
      "Torchvision Version:  0.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./data/hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 5\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=5, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.5716 Acc: 0.6885\n",
      "val Loss: 0.2964 Acc: 0.9346\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.4287 Acc: 0.8156\n",
      "val Loss: 0.2280 Acc: 0.9542\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3759 Acc: 0.7992\n",
      "val Loss: 0.2147 Acc: 0.9346\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2761 Acc: 0.8730\n",
      "val Loss: 0.2324 Acc: 0.9216\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.3189 Acc: 0.8607\n",
      "val Loss: 0.2267 Acc: 0.9346\n",
      "\n",
      "Training complete in 3m 51s\n",
      "Best val Acc: 0.954248\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.7112 Acc: 0.5246\n",
      "val Loss: 0.7424 Acc: 0.6078\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.6352\n",
      "val Loss: 0.7473 Acc: 0.5882\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.7768 Acc: 0.5902\n",
      "val Loss: 0.7074 Acc: 0.5294\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.6455 Acc: 0.6475\n",
      "val Loss: 0.6084 Acc: 0.6667\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.6148\n",
      "val Loss: 0.9482 Acc: 0.6797\n",
      "\n",
      "Training complete in 4m 16s\n",
      "Best val Acc: 0.679739\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
