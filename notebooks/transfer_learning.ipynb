{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vh6Xra9NBBt-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "from torch import nn, optim\n",
        "from torch import tensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "from image_classification_simulation.data.office31_loader import Office31Loader\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvErkR0diAWo",
        "outputId": "fe1d2e49-d2a0-4442-faa6-8254e547030c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image size set to: 200\n"
          ]
        }
      ],
      "source": [
        "office_loader = Office31Loader(data_dir=\"../examples/data/amazon/images/\", hyper_params={\"num_workers\": 2, 'batch_size': 32})\n",
        "office_loader.setup('fit')\n",
        "train_loader = office_loader.train_dataloader()\n",
        "val_loader = office_loader.val_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhZlJdFZBluM",
        "outputId": "20237c51-80b8-4489-8181-33ada301137e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resnet(\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(in_features=512, out_features=31, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "def dfs_freeze(model):\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "def dfs_unfreeze(model):\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, feature_extractor: nn.Module):\n",
        "        super(Resnet, self).__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        layers = list(self.feature_extractor.children())[:-1]\n",
        "        self.feature_extractor = nn.Sequential(*layers)\n",
        "        # dfs_freeze(self.feature_extractor)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = torch.nn.Linear(512, 31)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch_images: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predict query labels using labeled support images.\n",
        "        \"\"\"\n",
        "        # Extract the features of support and query images\n",
        "        # self.feature_extractor.eval()\n",
        "        # with torch.no_grad():\n",
        "        z_x = self.feature_extractor.forward(batch_images)\n",
        "\n",
        "        z_x = self.flatten(z_x)\n",
        "        logits = self.linear1(z_x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = None\n",
        "convolutional_network = resnet18(pretrained=True)\n",
        "model = Resnet(convolutional_network)\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "sJHBTV_pGlwk"
      },
      "outputs": [],
      "source": [
        "def evaluate(\n",
        "  model,\n",
        "    test_loader):\n",
        "    \"\"\"\n",
        "    Returns the number of correct predictions of query labels, and the total number of predictions.\n",
        "    \"\"\"\n",
        "    preds, true  = [], []\n",
        "    correct, size = 0 , 0\n",
        "    model.eval()\n",
        "    for batch_images, batch_labels in test_loader:\n",
        "      logits = model(batch_images.to(device)).detach().data\n",
        "      probs = softmax(logits,1)\n",
        "      preds = torch.argmax(probs,1)\n",
        "      correct+= torch.sum( preds == batch_labels.to(device) ).item() \n",
        "      size+=batch_images.size(0)\n",
        "\n",
        "    return 100*correct / size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO_MRL0Oqu9u",
        "outputId": "25f6cd84-9217-4431-8e74-f78d5dfbdc78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "end of epoch 1 total loss is 3.1899641543626784 train accuracy is 14.313880126182966.\n",
            "Loss 3.1175014972686768 and validation accuracy 27.75800711743772: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 2 total loss is 2.9586816906929014 train accuracy is 33.12302839116719.\n",
            "Loss 2.8326778411865234 and validation accuracy 41.637010676156585: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 3 total loss is 2.7381107926368715 train accuracy is 46.17507886435331.\n",
            "Loss 2.59792160987854 and validation accuracy 53.736654804270465: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 4 total loss is 2.5267316937446593 train accuracy is 56.46687697160883.\n",
            "Loss 2.389148473739624 and validation accuracy 59.430604982206404: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 5 total loss is 2.328317728638649 train accuracy is 62.973186119873816.\n",
            "Loss 2.209064483642578 and validation accuracy 63.345195729537366: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 6 total loss is 2.1472518503665925 train accuracy is 66.95583596214512.\n",
            "Loss 2.048319101333618 and validation accuracy 65.83629893238434: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 7 total loss is 1.9853607147932053 train accuracy is 70.26813880126183.\n",
            "Loss 1.9017022848129272 and validation accuracy 65.83629893238434: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 8 total loss is 1.8422021746635437 train accuracy is 73.10725552050474.\n",
            "Loss 1.7689292430877686 and validation accuracy 67.25978647686833: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 9 total loss is 1.7160312429070472 train accuracy is 74.9211356466877.\n",
            "Loss 1.6474299430847168 and validation accuracy 68.32740213523131: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 10 total loss is 1.6047453865408898 train accuracy is 76.06466876971609.\n",
            "Loss 1.538118600845337 and validation accuracy 69.3950177935943: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 11 total loss is 1.5064005628228188 train accuracy is 76.85331230283911.\n",
            "Loss 1.4391030073165894 and validation accuracy 70.4626334519573: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 12 total loss is 1.4189006194472313 train accuracy is 77.87854889589906.\n",
            "Loss 1.348413348197937 and validation accuracy 71.17437722419929: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 13 total loss is 1.3407276079058648 train accuracy is 78.66719242902208.\n",
            "Loss 1.2654041051864624 and validation accuracy 71.53024911032028: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 14 total loss is 1.2704561442136764 train accuracy is 79.3769716088328.\n",
            "Loss 1.1880426406860352 and validation accuracy 72.59786476868328: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 15 total loss is 1.206956508010626 train accuracy is 80.20504731861199.\n",
            "Loss 1.117026925086975 and validation accuracy 73.30960854092527: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 16 total loss is 1.149243202060461 train accuracy is 81.15141955835962.\n",
            "Loss 1.0506494045257568 and validation accuracy 74.02135231316726: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 17 total loss is 1.09658517614007 train accuracy is 81.94006309148266.\n",
            "Loss 0.9886117577552795 and validation accuracy 74.37722419928825: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 18 total loss is 1.048294548690319 train accuracy is 82.25552050473186.\n",
            "Loss 0.9314042925834656 and validation accuracy 74.73309608540926: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 19 total loss is 1.003782007098198 train accuracy is 82.72870662460568.\n",
            "Loss 0.8777152299880981 and validation accuracy 75.08896797153025: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 20 total loss is 0.9626426517963409 train accuracy is 83.39905362776025.\n",
            "Loss 0.8278117775917053 and validation accuracy 75.44483985765125: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 21 total loss is 0.9244686186313629 train accuracy is 83.87223974763407.\n",
            "Loss 0.7816786766052246 and validation accuracy 75.44483985765125: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 22 total loss is 0.8889092810451984 train accuracy is 84.26656151419559.\n",
            "Loss 0.7379538416862488 and validation accuracy 75.44483985765125: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 23 total loss is 0.8556540869176388 train accuracy is 84.93690851735016.\n",
            "Loss 0.6970133781433105 and validation accuracy 75.44483985765125: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 24 total loss is 0.8245064064860343 train accuracy is 85.64668769716089.\n",
            "Loss 0.6585983633995056 and validation accuracy 75.80071174377224: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 25 total loss is 0.79520173817873 train accuracy is 86.15930599369085.\n",
            "Loss 0.6221011877059937 and validation accuracy 76.51245551601423: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 26 total loss is 0.7675548013299703 train accuracy is 86.75078864353313.\n",
            "Loss 0.5880621671676636 and validation accuracy 76.86832740213524: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 27 total loss is 0.7413879863917827 train accuracy is 87.34227129337539.\n",
            "Loss 0.556510865688324 and validation accuracy 77.58007117437722: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 28 total loss is 0.7166021335870028 train accuracy is 87.77602523659306.\n",
            "Loss 0.5267896056175232 and validation accuracy 77.58007117437722: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 29 total loss is 0.6930437929928303 train accuracy is 88.24921135646687.\n",
            "Loss 0.4992710053920746 and validation accuracy 77.93594306049822: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 30 total loss is 0.6706428371369839 train accuracy is 88.52523659305994.\n",
            "Loss 0.4730747938156128 and validation accuracy 77.93594306049822: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 31 total loss is 0.6492415685206652 train accuracy is 88.99842271293376.\n",
            "Loss 0.4489298462867737 and validation accuracy 77.93594306049822: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 32 total loss is 0.6287979304790496 train accuracy is 89.43217665615143.\n",
            "Loss 0.4265059530735016 and validation accuracy 77.93594306049822: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 33 total loss is 0.6093006525188684 train accuracy is 89.78706624605678.\n",
            "Loss 0.40565550327301025 and validation accuracy 77.93594306049822: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 34 total loss is 0.5905868526548147 train accuracy is 90.1813880126183.\n",
            "Loss 0.385766863822937 and validation accuracy 78.29181494661921: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 35 total loss is 0.5726709775626659 train accuracy is 90.53627760252365.\n",
            "Loss 0.36762216687202454 and validation accuracy 79.00355871886121: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 36 total loss is 0.5554410621523858 train accuracy is 90.81230283911673.\n",
            "Loss 0.3505362570285797 and validation accuracy 79.00355871886121: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 37 total loss is 0.5388548277318478 train accuracy is 91.08832807570978.\n",
            "Loss 0.3349398374557495 and validation accuracy 79.00355871886121: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 38 total loss is 0.5228945784270763 train accuracy is 91.60094637223975.\n",
            "Loss 0.32025039196014404 and validation accuracy 78.64768683274022: \n",
            "learning rate updated to :  [0.0001]\n",
            "end of epoch 39 total loss is 0.5075106449425221 train accuracy is 91.99526813880126.\n",
            "Loss 0.306475967168808 and validation accuracy 78.64768683274022: \n",
            "learning rate updated to :  [0.0001]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-e002.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000005vscode-remote?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-e002.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000005vscode-remote?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcn-e002.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000005vscode-remote?line=33'>34</a>\u001b[0m loss_value \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-e002.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000005vscode-remote?line=34'>35</a>\u001b[0m all_loss\u001b[39m.\u001b[39mappend(loss_value)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-e002.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000005vscode-remote?line=36'>37</a>\u001b[0m probs \u001b[39m=\u001b[39m softmax(logits,\u001b[39m1\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam( filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
        "# optimizer = optim.Adam(  model.parameters(), lr=2e-5)\n",
        "optimizer = optim.SGD( model.parameters(), lr=0.0001, momentum=0.9)\n",
        "# optimizer = optim.SGD( filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, momentum=0.9)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=0.9, gamma=0.1)\n",
        "\n",
        "\n",
        "# Train the model yourself with this cell\n",
        "log_update_frequency = 1\n",
        "\n",
        "all_loss = []\n",
        "model.train()\n",
        "epochs = 100\n",
        "for epoch in range(1,epochs):\n",
        "  preds, true  = [], []\n",
        "  correct = 0\n",
        "  t=0\n",
        "  for batch_images,batch_labels in train_loader:\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(\n",
        "        batch_images.to(device)\n",
        "    )\n",
        "\n",
        "    loss = criterion(logits, batch_labels.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    loss_value = loss.item()\n",
        "    all_loss.append(loss_value)\n",
        "\n",
        "    probs = softmax(logits,1)\n",
        "    preds = torch.argmax(probs,1)#.tolist()\n",
        "    correct+= torch.sum( preds == batch_labels.to(device) ).item() \n",
        "    t+=batch_labels.size(0)\n",
        "\n",
        "  train_accuracy = 100 * correct/t\n",
        "  print('end of epoch {} total loss is {} train accuracy is {}.'.format(epoch,np.array(all_loss).mean(), train_accuracy ) )\n",
        "  all_loss = []\n",
        "  correct=0\n",
        "  t=0\n",
        "  \n",
        "  # if epoch == 3:\n",
        "  #   dfs_unfreeze(model)\n",
        "  #   print('weights are unfrozen!')\n",
        "\n",
        "  if epoch % log_update_frequency == 0:\n",
        "    print('Loss {} and validation accuracy {}: '.format(loss_value, evaluate(model,val_loader) ) )\n",
        "    # scheduler.step()\n",
        "    print('learning rate updated to : ',scheduler.get_last_lr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84.34163701067615"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "office_loader.setup('test')\n",
        "test_loader = office_loader.test_dataloader()\n",
        "evaluate(model,val_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_classification_resnet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('test')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5290e27e2982e14914fc743eb271efd553283179009389fbf33907a815e7eb33"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
