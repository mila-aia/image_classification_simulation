{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vh6Xra9NBBt-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "from torch import nn, optim\n",
        "from torch import tensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "from image_classification_simulation.data.office31_loader import Office31Loader\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvErkR0diAWo",
        "outputId": "fe1d2e49-d2a0-4442-faa6-8254e547030c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image size set to: 224\n"
          ]
        }
      ],
      "source": [
        "office_loader = Office31Loader(\n",
        "    data_dir=\"../examples/data/domain_adaptation_images/amazon/images\",\n",
        "    eval_dir=\"../examples/data/domain_adaptation_images/dslr/images/\",\n",
        "    hyper_params={\"num_workers\": 2, 'batch_size': 32}\n",
        "    )\n",
        "office_loader.setup('fit')\n",
        "train_loader = office_loader.train_dataloader()\n",
        "val_loader = office_loader.val_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhZlJdFZBluM",
        "outputId": "20237c51-80b8-4489-8181-33ada301137e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resnet(\n",
            "  (loss_fn): CrossEntropyLoss()\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear): Linear(in_features=512, out_features=964, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from image_classification_simulation.models.resnet_baseline import Resnet\n",
        "\n",
        "hparams = {\n",
        "        \"size\": 964,\n",
        "        \"loss\": \"CrossEntropyLoss\",\n",
        "        \"pretrained\": True,\n",
        "        \"num_classes\": 964,\n",
        "    }\n",
        "model = Resnet(hparams).to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sJHBTV_pGlwk"
      },
      "outputs": [],
      "source": [
        "def evaluate(\n",
        "  model,\n",
        "    test_loader):\n",
        "    \"\"\"\n",
        "    Returns the number of correct predictions of query labels, and the total number of predictions.\n",
        "    \"\"\"\n",
        "    preds, true  = [], []\n",
        "    correct, size = 0 , 0\n",
        "    model.eval()\n",
        "    for batch_images, batch_labels in test_loader:\n",
        "      logits = model(batch_images.to(device)).detach().data\n",
        "      probs = softmax(logits,1)\n",
        "      preds = torch.argmax(probs,1)\n",
        "      correct+= torch.sum( preds == batch_labels.to(device) ).item() \n",
        "      size+=batch_images.size(0)\n",
        "\n",
        "    return 100*correct / size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO_MRL0Oqu9u",
        "outputId": "25f6cd84-9217-4431-8e74-f78d5dfbdc78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 36 members, which is less than n_splits=88.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 471, in __getitem__\n    return self.dataset[self.indices[idx]]\nIndexError: list index out of range\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c029.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c029.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m t\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c029.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000004vscode-remote?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_images,batch_labels \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c029.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000004vscode-remote?line=22'>23</a>\u001b[0m   model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c029.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/transfer_learning.ipynb#ch0000004vscode-remote?line=23'>24</a>\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1224\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
            "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1250\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1251\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
            "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/mila/s/sina.sarparast/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 471, in __getitem__\n    return self.dataset[self.indices[idx]]\nIndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "# from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam( filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
        "# optimizer = optim.Adam(  model.parameters(), lr=2e-5)\n",
        "optimizer = optim.SGD( model.parameters(), lr=0.0001, momentum=0.9)\n",
        "# optimizer = optim.SGD( filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, momentum=0.9)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=0.9, gamma=0.1)\n",
        "\n",
        "\n",
        "# Train the model yourself with this cell\n",
        "log_update_frequency = 1\n",
        "\n",
        "all_loss = []\n",
        "model.train()\n",
        "epochs = 100\n",
        "for epoch in range(1,epochs):\n",
        "  preds, true  = [], []\n",
        "  correct = 0\n",
        "  t=0\n",
        "  for batch_images,batch_labels in train_loader:\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(\n",
        "        batch_images.to(device)\n",
        "    )\n",
        "\n",
        "    loss = criterion(logits, batch_labels.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    loss_value = loss.item()\n",
        "    all_loss.append(loss_value)\n",
        "\n",
        "    probs = softmax(logits,1)\n",
        "    preds = torch.argmax(probs,1)#.tolist()\n",
        "    correct+= torch.sum( preds == batch_labels.to(device) ).item() \n",
        "    t+=batch_labels.size(0)\n",
        "\n",
        "  train_accuracy = 100 * correct/t\n",
        "  print('end of epoch {} total loss is {} train accuracy is {}.'.format(epoch,np.array(all_loss).mean(), train_accuracy ) )\n",
        "  all_loss = []\n",
        "  correct=0\n",
        "  t=0\n",
        "  \n",
        "  # if epoch == 3:\n",
        "  #   dfs_unfreeze(model)\n",
        "  #   print('weights are unfrozen!')\n",
        "\n",
        "  if epoch % log_update_frequency == 0:\n",
        "    print('Loss {} and validation accuracy {}: '.format(loss_value, evaluate(model,val_loader) ) )\n",
        "    # scheduler.step()\n",
        "    print('learning rate updated to : ',scheduler.get_last_lr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86.01895734597156"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "office_loader.setup('test')\n",
        "test_loader = office_loader.test_dataloader()\n",
        "evaluate(model,test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation on DSLR subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58.63453815261044"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "office_loader.setup('eval')\n",
        "eval_loader = office_loader.eval_dataloader()\n",
        "evaluate(model,eval_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "looks like that the model is not very good at adapting to the images with background in the DSLR dataset."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_classification_resnet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('test')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5290e27e2982e14914fc743eb271efd553283179009389fbf33907a815e7eb33"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
