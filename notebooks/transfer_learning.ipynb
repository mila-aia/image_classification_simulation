{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vh6Xra9NBBt-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "from torch import nn, optim\n",
        "from torch import tensor\n",
        "# import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "from image_classification_simulation.data.office31_loader import Office31Loader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvErkR0diAWo",
        "outputId": "fe1d2e49-d2a0-4442-faa6-8254e547030c"
      },
      "outputs": [],
      "source": [
        "\n",
        "office_loader = Office31Loader(data_dir=\"../examples/data/amazon\", hyper_params={\"num_workers\": 1, 'batch_size': 32})\n",
        "office_loader.setup()\n",
        "train_loader = office_loader.train_dataloader()\n",
        "val_loader = office_loader.val_dataloader()\n",
        "test_loader = office_loader.test_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhZlJdFZBluM",
        "outputId": "20237c51-80b8-4489-8181-33ada301137e"
      },
      "outputs": [],
      "source": [
        "def dfs_freeze(model):\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "def dfs_unfreeze(model):\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, feature_extractor: nn.Module):\n",
        "        super(Resnet, self).__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        # dfs_freeze(self.feature_extractor)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = torch.nn.Linear(1000, 512)\n",
        "        self.linear2 = torch.nn.Linear(512, office_loader.num_unique_labels)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch_images: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predict query labels using labeled support images.\n",
        "        \"\"\"\n",
        "        # Extract the features of support and query images\n",
        "        z_x = self.feature_extractor.forward(batch_images)\n",
        "        z_x = self.flatten(z_x)\n",
        "        z_x = self.linear1(z_x)\n",
        "        z_x = self.activation(z_x)\n",
        "        logits = self.linear2(z_x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = None\n",
        "convolutional_network = resnet18(pretrained=False)\n",
        "model = Resnet(convolutional_network)\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sJHBTV_pGlwk"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import softmax\n",
        "def evaluate(\n",
        "    test_loader):\n",
        "    \"\"\"\n",
        "    Returns the number of correct predictions of query labels, and the total number of predictions.\n",
        "    \"\"\"\n",
        "    preds, true  = [], []\n",
        "    for batch_images, batch_labels in test_loader:\n",
        "      logits = model(batch_images.to(device)).detach().data\n",
        "      probs = softmax(logits,0)\n",
        "      preds.extend( torch.argmax(probs,1).tolist() )\n",
        "      true.extend(batch_labels.tolist())\n",
        "\n",
        "    preds, true = np.array(preds), np.array(true)\n",
        "    return 100*( preds == true ).sum().item() / len(true)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO_MRL0Oqu9u",
        "outputId": "25f6cd84-9217-4431-8e74-f78d5dfbdc78"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam( filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
        "# optimizer = optim.SGD( model.parameters(), lr=0.0001, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=0.9, gamma=0.1)\n",
        "\n",
        "\n",
        "# Train the model yourself with this cell\n",
        "log_update_frequency = 1\n",
        "\n",
        "all_loss = []\n",
        "model.train()\n",
        "epochs = 100\n",
        "for epoch in range(1,epochs):\n",
        "  preds, true  = [], []\n",
        "  for batch_images,batch_labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(\n",
        "        batch_images.to(device)\n",
        "    )\n",
        "\n",
        "    loss = criterion(logits, batch_labels.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    loss_value = loss.item()\n",
        "    all_loss.append(loss_value)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(logits,0)\n",
        "    preds.extend( torch.argmax(probs,1).tolist() )\n",
        "    true.extend(batch_labels.tolist())\n",
        "\n",
        "  preds, true = np.array(preds), np.array(true)\n",
        "  train_accuracy = 100*( preds == true ).sum().item() / len(true)\n",
        "  print('end of epoch {} total loss is {} train accuracy is {}.'.format(epoch,np.array(all_loss).sum()/epochs, train_accuracy ) )\n",
        "\n",
        "  # if epoch == 3:\n",
        "  #   dfs_unfreeze(model)\n",
        "  #   print('weights are unfrozen!')\n",
        "\n",
        "  if epoch % log_update_frequency == 0:\n",
        "    print('Loss {} and validation accuracy {}: '.format(loss_value, evaluate(val_loader) ) )\n",
        "    scheduler.step()\n",
        "    print('learning rate updated to : ',scheduler.get_last_lr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjpdz9UNYGTW",
        "outputId": "8f42b3a1-0873-48fa-bef2-cded14eebd15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31.66489172878949"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_classification_resnet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('test')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5290e27e2982e14914fc743eb271efd553283179009389fbf33907a815e7eb33"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
