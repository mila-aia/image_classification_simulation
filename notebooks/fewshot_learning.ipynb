{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torch import nn, optim\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "from image_classification_simulation.data.office31_loader import Office31Loader\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install easyfsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.samplers import TaskSampler\n",
    "from easyfsl.utils import plot_images, sliding_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size set to: 200\n"
     ]
    }
   ],
   "source": [
    "office_loader = Office31Loader(data_dir=\"../examples/data/amazon/images/\", hyper_params={\"num_workers\": 2, 'batch_size': 32})\n",
    "office_loader.setup('fit',0.2)\n",
    "train_loader = office_loader.train_fewshot_loader()\n",
    "val_loader = office_loader.val_fewshot_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict query labels using labeled support images.\n",
    "        \"\"\"\n",
    "        # Extract the features of support and query images\n",
    "        z_support = self.backbone.forward(support_images)\n",
    "        z_query = self.backbone.forward(query_images)\n",
    "\n",
    "        # Infer the number of different classes from the labels of the support set\n",
    "        n_way = len(torch.unique(support_labels))\n",
    "        # Prototype i is the mean of all instances of features corresponding to labels == i\n",
    "        self.z_proto = torch.cat(\n",
    "            [\n",
    "                z_support[torch.nonzero(support_labels == label)].mean(0)\n",
    "                for label in range(n_way)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Compute the euclidean distance from queries to prototypes\n",
    "        dists = torch.cdist(z_query, self.z_proto)\n",
    "\n",
    "        # And here is the super complicated operation to transform those distances into classification scores!\n",
    "        scores = -dists\n",
    "        return scores\n",
    "\n",
    "\n",
    "convolutional_network = resnet18(pretrained=True)\n",
    "convolutional_network.fc = nn.Flatten()\n",
    "print(convolutional_network)\n",
    "\n",
    "model = PrototypicalNetworks(convolutional_network).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def fit(\n",
    "    support_images: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    query_images: torch.Tensor,\n",
    "    query_labels: torch.Tensor,\n",
    ") -> float:\n",
    "    optimizer.zero_grad()\n",
    "    classification_scores = model(\n",
    "        support_images.cuda(), support_labels.cuda(), query_images.cuda()\n",
    "    )\n",
    "\n",
    "    loss = criterion(classification_scores, query_labels.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=42'>43</a>\u001b[0m             correct_predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m correct\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=44'>45</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=45'>46</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel tested on \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data_loader)\u001b[39m}\u001b[39;00m\u001b[39m tasks. Accuracy: \u001b[39m\u001b[39m{\u001b[39;00m(\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct_predictions\u001b[39m/\u001b[39mtotal_predictions)\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=46'>47</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=49'>50</a>\u001b[0m evaluate(val_loader)\n",
      "\u001b[1;32m/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb Cell 7'\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=28'>29</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m episode_index, (\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=30'>31</a>\u001b[0m         support_images,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=31'>32</a>\u001b[0m         support_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=32'>33</a>\u001b[0m         query_images,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=33'>34</a>\u001b[0m         query_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=34'>35</a>\u001b[0m         class_ids,\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=35'>36</a>\u001b[0m     ) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39;49m(data_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data_loader)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=37'>38</a>\u001b[0m         correct, total \u001b[39m=\u001b[39m evaluate_on_one_task(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=38'>39</a>\u001b[0m             support_images, support_labels, query_images, query_labels\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=39'>40</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-a009.server.mila.quebec/home/mila/s/sina.sarparast/projects/image_classification_simulation/notebooks/clustering.ipynb#ch0000006vscode-remote?line=41'>42</a>\u001b[0m         total_predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:965\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    963\u001b[0m _utils\u001b[39m.\u001b[39msignal_handling\u001b[39m.\u001b[39m_set_SIGCHLD_handler()\n\u001b[1;32m    964\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_pids_set \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset(loader, first_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:996\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[39m# prime the prefetch loop\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_factor \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers):\n\u001b[0;32m--> 996\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_put_index()\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1230\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefetch_factor \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers\n\u001b[1;32m   1229\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1230\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 521\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter)\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/easyfsl/samplers/task_sampler.py:53\u001b[0m, in \u001b[0;36mTaskSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[List[\u001b[39mint\u001b[39m]]:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_tasks):\n\u001b[1;32m     52\u001b[0m         \u001b[39myield\u001b[39;00m torch\u001b[39m.\u001b[39mcat(\n\u001b[0;32m---> 53\u001b[0m             [\n\u001b[1;32m     54\u001b[0m                 \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m     55\u001b[0m                 torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     56\u001b[0m                     random\u001b[39m.\u001b[39msample(\n\u001b[1;32m     57\u001b[0m                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems_per_label[label], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_shot \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_query\n\u001b[1;32m     58\u001b[0m                     )\n\u001b[1;32m     59\u001b[0m                 )\n\u001b[1;32m     60\u001b[0m                 \u001b[39m# pylint: enable=not-callable\u001b[39;00m\n\u001b[1;32m     61\u001b[0m                 \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m random\u001b[39m.\u001b[39msample(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems_per_label\u001b[39m.\u001b[39mkeys(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_way)\n\u001b[1;32m     62\u001b[0m             ]\n\u001b[1;32m     63\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/site-packages/easyfsl/samplers/task_sampler.py:56\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[List[\u001b[39mint\u001b[39m]]:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_tasks):\n\u001b[1;32m     52\u001b[0m         \u001b[39myield\u001b[39;00m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m     53\u001b[0m             [\n\u001b[1;32m     54\u001b[0m                 \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m     55\u001b[0m                 torch\u001b[39m.\u001b[39mtensor(\n\u001b[0;32m---> 56\u001b[0m                     random\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m     57\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems_per_label[label], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_shot \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_query\n\u001b[1;32m     58\u001b[0m                     )\n\u001b[1;32m     59\u001b[0m                 )\n\u001b[1;32m     60\u001b[0m                 \u001b[39m# pylint: enable=not-callable\u001b[39;00m\n\u001b[1;32m     61\u001b[0m                 \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m random\u001b[39m.\u001b[39msample(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems_per_label\u001b[39m.\u001b[39mkeys(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_way)\n\u001b[1;32m     62\u001b[0m             ]\n\u001b[1;32m     63\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.conda/envs/test/lib/python3.8/random.py:363\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    361\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(population)\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m k \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n:\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSample larger than population or is negative\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    364\u001b[0m result \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m k\n\u001b[1;32m    365\u001b[0m setsize \u001b[39m=\u001b[39m \u001b[39m21\u001b[39m        \u001b[39m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "def evaluate_on_one_task(\n",
    "    support_images: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    query_images: torch.Tensor,\n",
    "    query_labels: torch.Tensor,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the number of correct predictions of query labels, and the total number of predictions.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        torch.max(\n",
    "            model(support_images.cuda(), support_labels.cuda(), query_images.cuda())\n",
    "            .detach()\n",
    "            .data,\n",
    "            1,\n",
    "        )[1]\n",
    "        == query_labels.cuda()\n",
    "    ).sum().item(), len(query_labels)\n",
    "\n",
    "\n",
    "def evaluate(data_loader: DataLoader):\n",
    "    # We'll count everything and compute the ratio at the end\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # eval mode affects the behaviour of some layers (such as batch normalization or dropout)\n",
    "    # no_grad() tells torch not to keep in memory the whole computational graph (it's more lightweight this way)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            class_ids,\n",
    "        ) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "            correct, total = evaluate_on_one_task(\n",
    "                support_images, support_labels, query_images, query_labels\n",
    "            )\n",
    "\n",
    "            total_predictions += total\n",
    "            correct_predictions += correct\n",
    "\n",
    "    print(\n",
    "        f\"Model tested on {len(data_loader)} tasks. Accuracy: {(100 * correct_predictions/total_predictions):.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "evaluate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:20<00:00,  1.25it/s, loss=0.331]\n"
     ]
    }
   ],
   "source": [
    "# Train the model yourself with this cell\n",
    "\n",
    "log_update_frequency = 10\n",
    "\n",
    "all_loss = []\n",
    "model.train()\n",
    "with tqdm(enumerate(train_loader), total=len(train_loader)) as tqdm_train:\n",
    "    for episode_index, (\n",
    "        support_images,\n",
    "        support_labels,\n",
    "        query_images,\n",
    "        query_labels,\n",
    "        _,\n",
    "    ) in tqdm_train:\n",
    "        loss_value = fit(support_images, support_labels, query_images, query_labels)\n",
    "        all_loss.append(loss_value)\n",
    "\n",
    "        if episode_index % log_update_frequency == 0:\n",
    "            tqdm_train.set_postfix(loss=sliding_average(all_loss, log_update_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:38<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested on 400 tasks. Accuracy: 70.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.z_proto.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5290e27e2982e14914fc743eb271efd553283179009389fbf33907a815e7eb33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
