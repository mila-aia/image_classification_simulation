{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from image_classification_simulation.data.office31_loader import Office31Loader\n",
    "from image_classification_simulation.models.clustering_tools import show_grid_images\n",
    "from image_classification_simulation.image_search import ImageSimilaritySearch\n",
    "from image_classification_simulation.utils.visualization_utils import show_grid_images\n",
    "from image_classification_simulation.models.clustering_tools import get_clustering_metrics\n",
    "from image_classification_simulation.models.clustering_tools import eval_clustering_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"num_workers\": 2,\n",
    "    'batch_size': 32,\n",
    "    \"image_size\":224,\n",
    "    \"train_test_split\":-1,\n",
    "}\n",
    "office_loader = Office31Loader(\n",
    "    data_dir=\"../examples/data/domain_adaptation_images/amazon/images/\",\n",
    "    eval_dir=\"../examples/data/domain_adaptation_images/dslr/images/\",\n",
    "     hyper_params=hparams)\n",
    "# office_loader.setup('fit')\n",
    "# train_loader = office_loader.train_dataloader()\n",
    "# val_loader = office_loader.val_dataloader()\n",
    "# test_loader = office_loader.test_dataloader()\n",
    "# # /network/projects/aia/img_classif_sim/vit/output/best_model\n",
    "office_loader.setup('eval')\n",
    "eval_loader = office_loader.eval_dataloader(shuffle=False)\n",
    "office_loader.setup('infer')\n",
    "train_loader = office_loader.train_dataloader(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hparams_resnet = {\n",
    "    \"clustering_alg\": \"nn\",\n",
    "    \"num_neighbors\":20,\n",
    "    \"radius\":0.5,\n",
    "    \"n_jobs\":2,\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"batch_size\": 100,\n",
    "    \"pretrained\": True,\n",
    "    \"num_classes\": 31,\n",
    "    \"path_to_model\": \"../examples/resnet/output/best_model/model.ckpt\",\n",
    "    \"architecture\": \"resnet\",\n",
    "    \"num_clusters\": 31,\n",
    "    \"random_state\": 0,\n",
    "    \"clustering_batch_size\": 100,\n",
    "    \"size\": 256,\n",
    "    \"reassignment_ratio\": 0.05,\n",
    "    \"path_cluster_ids\": \"../debug/dataset_cluster_ids.csv\",\n",
    "}\n",
    "hparams_vit = {\n",
    "    # \"clustering_alg\": \"MiniBatchKMeans\",\n",
    "    \"clustering_alg\": \"nn\",\n",
    "    \"num_neighbors\":20,\n",
    "    \"radius\":0.5,\n",
    "    \"n_jobs\":2,\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"pretrained\": True,\n",
    "    \"batch_size\": 100,\n",
    "    \"num_classes\": 31,\n",
    "    \"path_to_model\": \"/network/projects/aia/img_classif_sim/vit/output/best_model/model.ckpt\",\n",
    "    \"architecture\": \"vit\",\n",
    "    \"num_clusters\": 100,\n",
    "    \"random_state\": 0,\n",
    "    \"clustering_batch_size\": 1024,\n",
    "    \"reassignment_ratio\": 0.01,\n",
    "    \"init\":'random',\n",
    "    \"path_cluster_ids\": \"../debug/dataset_cluster_ids.csv\",\n",
    "}\n",
    "hparams_ae = {\n",
    "    \"clustering_alg\": \"MiniBatchKMeans\",\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"pretrained\": True,\n",
    "    \"batch_size\": 100,\n",
    "    \"num_channels\": 3,\n",
    "    \"num_classes\": 31,\n",
    "    \"path_to_model\": \"/network/projects/aia/img_classif_sim/conv_ae/output/best_model/model.ckpt\",\n",
    "    \"architecture\": \"conv_ae\",\n",
    "    \"num_clusters\": 32,\n",
    "    \"random_state\": 0,\n",
    "    \"clustering_batch_size\": 100,\n",
    "    \"reassignment_ratio\": 0.05,\n",
    "    \"path_cluster_ids\": \"../debug/dataset_cluster_ids.csv\",\n",
    "}\n",
    "hparams_cnn = {\n",
    "        \"clustering_alg\": \"nn\",\n",
    "        \"num_neighbors\":20,\n",
    "        \"radius\":0.5,\n",
    "        \"n_jobs\":2,\n",
    "        \"loss\": \"CrossEntropyLoss\",\n",
    "        \"batch_size\": 124,\n",
    "        \"num_channels\": 3,\n",
    "        \"pretrained\": True,\n",
    "        \"num_classes\": 31,\n",
    "        \"img_size\": 224,\n",
    "        \"path_to_model\": \"/network/projects/aia/img_classif_sim/classic_cnn/output/best_model/model.ckpt\",\n",
    "        \"architecture\": \"classic-cnn\",\n",
    "        \"num_clusters\": 31,\n",
    "        \"random_state\": 0,\n",
    "        \"clustering_batch_size\": 124,\n",
    "        \"reassignment_ratio\": 0.01,\n",
    "        \"path_cluster_ids\": \"../debug/dataset_cluster_ids.csv\",\n",
    "    }\n",
    "\n",
    "archs = {\n",
    "    \"resnet\": hparams_resnet,\n",
    "    \"vit\": hparams_vit,\n",
    "    # \"ae\": hparams_ae,\n",
    "    \"cnn\":hparams_cnn\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_true = [label for image, label in office_loader.eval_set]\n",
    "len(labels_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = image_search.predict(office_loader.eval_dataloader())\n",
    "len(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following metrics do not work when we are using nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rand_score': 0.024261940161551716,\n",
       " 'adjusted_rand_score': 0.024261940161551716,\n",
       " 'mutual_info_score': 0.5971366373315987}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = get_clustering_metrics(labels_true, labels_pred)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rand_score': 0.03455624029458484,\n",
       " 'adjusted_rand_score': 0.03455624029458484,\n",
       " 'mutual_info_score': 0.6542970012509423}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use either images from the evaluation or the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../examples/data/domain_adaptation_images/amazon/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = '../examples/data/domain_adaptation_images/dslr/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for arch in archs:\n",
    "    image_search = ImageSimilaritySearch(archs[arch], office_loader)\n",
    "    image_search.setup()\n",
    "    for class_name in office_loader.dataset.class_to_idx:\n",
    "        print(class_name)\n",
    "        path = eval_dir+\"{}/frame_0001.jpg\".format(class_name)\n",
    "        query_res = image_search.find_similar_images(path,None)\n",
    "        fig,_ = show_grid_images(\n",
    "            query_res['image_path'].tolist(),\n",
    "            num_rows=5,\n",
    "            num_cols=5,\n",
    "            )\n",
    "        fig.savefig('./results/'+arch+'/'+class_name+'.png',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> model loaded successfully!\n",
      ">>> clustering initialized successfully!\n",
      ">>> dataset loaded successfully!\n",
      ">>> clustering model fitted successfully!\n",
      ">>> setup completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5144578313253012"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_search = ImageSimilaritySearch(archs['resnet'], office_loader)\n",
    "image_search.setup()\n",
    "class_ids = office_loader.labels\n",
    "true_labels = [label for img, label in office_loader.eval_set]\n",
    "eval_clustering_performance(\n",
    "        class_ids,\n",
    "        true_labels,\n",
    "        image_search.clustering.find_neighbors,\n",
    "        eval_loader,\n",
    "        5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> model loaded successfully!\n",
      ">>> clustering initialized successfully!\n",
      ">>> dataset loaded successfully!\n",
      ">>> clustering model fitted successfully!\n",
      ">>> setup completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7570281124497992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_search = ImageSimilaritySearch(archs['vit'], office_loader)\n",
    "image_search.setup()\n",
    "class_ids = office_loader.labels\n",
    "true_labels = [label for img, label in office_loader.eval_set]\n",
    "eval_clustering_performance(\n",
    "        class_ids,\n",
    "        true_labels,\n",
    "        image_search.clustering.find_neighbors,\n",
    "        eval_loader,\n",
    "        5\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5290e27e2982e14914fc743eb271efd553283179009389fbf33907a815e7eb33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
