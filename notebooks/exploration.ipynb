{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchinfo\n",
    "import matplotlib as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.Omniglot(\n",
    "    root=\"./data\", download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "image, label = dataset[0]\n",
    "print(type(image))  # torch.Tensor\n",
    "print(type(label))  # int\n",
    "print(image[0].size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "train_set = torchvision.datasets.Omniglot(\n",
    "    root=\"./data\",\n",
    "    background=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize([int(image_size), int(image_size)]),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "test_set = torchvision.datasets.Omniglot(\n",
    "    root=\"./data\",\n",
    "    background=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            # Omniglot images have 1 channel, but our model will expect 3-channel images\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize([int(image_size), int(image_size)]),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        shortcut = self.shortcut(input)\n",
    "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
    "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
    "        input = input + shortcut\n",
    "        return nn.ReLU()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resblock, outputs=1623):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 8, kernel_size=3, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            resblock(8, 8, downsample=False),\n",
    "            resblock(8, 8, downsample=False)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            resblock(8, 16, downsample=True),\n",
    "            resblock(16, 16, downsample=False)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            resblock(16, 32, downsample=True),\n",
    "            resblock(32, 32, downsample=False)\n",
    "        )\n",
    "\n",
    "        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(32, outputs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.layer0(input)\n",
    "        input = self.layer1(input)\n",
    "        input = self.layer2(input)\n",
    "        input = self.layer3(input)\n",
    "        input = self.gap(input)\n",
    "        input = torch.flatten(input)\n",
    "        input = self.fc(input)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mini_resnet = MiniResNet(1, ResBlock, outputs=1623)\n",
    "mini_resnet.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "print(torchinfo.summary(mini_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
